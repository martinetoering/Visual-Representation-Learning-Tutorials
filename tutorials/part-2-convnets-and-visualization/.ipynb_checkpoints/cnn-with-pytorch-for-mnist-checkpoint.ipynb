{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# Introduction to Convolutional Neural Networks\n",
    "\n",
    "This notebook aims at discovering Convolutional Neural Networks (CNNs/ConvNet). We will briefly cover what Convolutional Neural networks are and set up a basic CNN for image classification on CIFAR-10.\n",
    "\n",
    "# Part 1: Basic Modules \n",
    "\n",
    "Useful resources: \n",
    "* [Stanford CS231n](http://cs231n.github.io/convolutional-networks/)\n",
    "* [Colah's blog](https://colah.github.io/posts/2014-10-Visualizing-MNIST/)\n",
    "* [Intuitive explanation ConvNets](https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/)\n",
    "\n",
    "## Modules\n",
    "\n",
    "**Convolutional operation** : First let's clarify briefly how we can perform the convolutional operation on an image. For that we need to define a **kernel** which is a small matrix of size 5 \\* 5 for example. To perform the convolution operation, we just need to slide the kernel along the image horizontally and vertically and do the dot product of the kernel and the small portion of the image.\n",
    "\n",
    "**Pooling** : the convolutional operation give an output of the same size of the input image. To reduce the size of the image and thus reduce the number of paramers in the model we perform a Pooling operation. The pooling operation need a window size.. By sliding the window along the image, we compute the mean or the max of the portion of the image inside the window in case of MeanPooling or MaxPooling.\n",
    "\n",
    "**Stride** is the number of pixels to pass at a time when sliding the convolutional kernel.  \n",
    "\n",
    "**Padding** to preserve exactly the size of the input image, it is useful to add a zero padding on the border of the image. \n",
    "\n",
    "\n",
    "**To remember** : What makes a CNN so interesting for images is that it is invariant by translation and for each convolutional layer we only need to store the kernels. Thus we can stack a lot of layers to learn deep features without having too much parameters that would make a model untrainnable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "810c7b5869b3c704d5a5a7e28289133c27c5790c"
   },
   "source": [
    "# Part 1: Basic Modules "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0dd01423ecc2b3c46c42aaa033ad8556ba029dc9"
   },
   "source": [
    "## Explanation\n",
    "\n",
    "To better understand convolutional neural network I recommend the great section on it here : http://cs231n.github.io/convolutional-networks/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9baaa52b6b9b6b8f8287a10fcc801606848fb726"
   },
   "source": [
    "## Data loader\n",
    "\n",
    "Since a CNN needs a image shape as input let's reshape our flatten images to real image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5e84347012cd6abc2f6f46299aab08b0c89563ee"
   },
   "outputs": [],
   "source": [
    "torch_X_train = torch_X_train.view(-1, 1,28,28).float()\n",
    "torch_X_test = torch_X_test.view(-1,1,28,28).float()\n",
    "print(torch_X_train.shape)\n",
    "print(torch_X_test.shape)\n",
    "\n",
    "# Pytorch train and test sets\n",
    "train = torch.utils.data.TensorDataset(torch_X_train,torch_y_train)\n",
    "test = torch.utils.data.TensorDataset(torch_X_test,torch_y_test)\n",
    "\n",
    "# data loader\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = BATCH_SIZE, shuffle = False)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size = BATCH_SIZE, shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c669e5f557724154d9f4f5f8b5d0d6c9b676d551"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=5)\n",
    "        self.conv3 = nn.Conv2d(32,64, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(3*3*64, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        #x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = F.relu(F.max_pool2d(self.conv3(x),2))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = x.view(-1,3*3*64 )\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    " \n",
    "cnn = CNN()\n",
    "print(cnn)\n",
    "\n",
    "it = iter(train_loader)\n",
    "X_batch, y_batch = next(it)\n",
    "print(cnn.forward(X_batch).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "797cbe3cff05d8bdb42f3273a06839b18daf5266"
   },
   "outputs": [],
   "source": [
    "fit(cnn,train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "890dfc8d29ac70df919807b275b38112ca9297ab"
   },
   "outputs": [],
   "source": [
    "evaluate(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3703af54a320fd81bfa426be17655a3cebec5ac4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "071e27e26196cbc58a8aee71324ad4b02222c8d0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
